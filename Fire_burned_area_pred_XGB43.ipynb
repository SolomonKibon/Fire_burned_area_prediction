{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOs9T96e9XpFB2zD/HK+Z2e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Project Title: Wildfire Prediction Challenge\n","#Name: Kibon Kiprono Solomon\n","#Date: 25/07/2024\n","Problem Statement: Each year, thousands of fires blaze across the African continent. Some are natural occurrences, part of a ‘fire cycle’ that can actually benefit some dryland ecosystems. Many are started intentionally, used to clear land or to prepare fields for planting. And some are wildfires, which can rage over large areas and cause huge amounts of damage. Whatever the cause, fires pour vast amounts of CO2 into the atmosphere, along with smoke that degrades air quality for those living downwind.\n","\n","Figuring out the dynamics that influence where and when these fires occur can help us to better understand their effects. And predicting how these dynamics will play out in the future, under different climatic conditions, could prove extremely useful.\n","\n","Project goal: The objective of this challenge is to create a machine-learning model capable of predicting the burned area in different locations over 2014 to 2016.\n"],"metadata":{"id":"d_Ld4F9P_ePP"}},{"cell_type":"code","source":["# Upload the dataset\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from xgboost import XGBRegressor\n","import scipy.stats as stats\n","\n","# Load datasets\n","train = pd.read_csv('/content/drive/My Drive/fire-extent-prediction-challenge/Train.csv')\n","test = pd.read_csv('/content/drive/My Drive/fire-extent-prediction-challenge/Test.csv')\n","ss = pd.read_csv('/content/drive/My Drive/fire-extent-prediction-challenge/SampleSubmission.csv')\n","\n","# Preprocess the data\n","train['date'] = pd.to_datetime(train['ID'].apply(lambda x: x.split('_')[1]))\n","train['year'] = train['date'].dt.year\n","train['month'] = train['date'].dt.month\n","train['day'] = train['date'].dt.day\n","\n","test['date'] = pd.to_datetime(test['ID'].apply(lambda x: x.split('_')[1]))\n","test['year'] = test['date'].dt.year\n","test['month'] = test['date'].dt.month\n","test['day'] = test['date'].dt.day\n","\n","# Drop unnecessary columns and split data\n","X = train.drop(['burn_area', 'ID', 'date', 'day'], axis=1)\n","y = train['burn_area']\n","\n","# Split data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","\n","# Convert back to DataFrame to retain feature names\n","X_train = pd.DataFrame(X_train, columns=X.columns)\n","X_val = pd.DataFrame(X_val, columns=X.columns)\n","\n","# Define the model\n","xgb_reg = XGBRegressor(random_state=42)\n","\n","# Define the parameter grid for hyperparameter tuning using RandomizedSearchCV\n","param_dist = {\n","    'n_estimators': stats.randint(50, 400),\n","    'learning_rate': stats.uniform(0.01, 0.3),\n","    'max_depth': stats.randint(3, 10),\n","    'subsample': stats.uniform(0.6, 0.4),\n","    'colsample_bytree': stats.uniform(0.6, 0.4),\n","    'reg_alpha': stats.uniform(0, 1),\n","    'reg_lambda': stats.uniform(0, 1)\n","}\n","\n","# Perform RandomizedSearchCV\n","random_search = RandomizedSearchCV(estimator=xgb_reg, param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1, scoring='neg_mean_squared_error', random_state=42)\n","random_search.fit(X_train, y_train)\n","\n","# Get the best model and print best parameters\n","best_model = random_search.best_estimator_\n","print(\"Best parameters found: \", random_search.best_params_)\n","\n","# Print feature importances\n","feature_importances = best_model.feature_importances_\n","importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n","importance_df = importance_df.sort_values(by='Importance', ascending=False)\n","print(\"Feature importances:\")\n","print(importance_df)\n","\n","# Select top important features (for example, top 8 features)\n","top_features = importance_df.head(8)['Feature'].values\n","print(\"Top features selected for prediction:\", top_features)\n","\n","# Filter training and validation data to include only top features\n","X_train_top = X_train[top_features]\n","X_val_top = X_val[top_features]\n","\n","# Retrain the best model using only top features\n","best_model.fit(X_train_top, y_train)\n","\n","# Make predictions on the validation set\n","y_val_pred = best_model.predict(X_val_top)\n","\n","# Calculate the Mean Squared Error and Root Mean Squared Error\n","mse = mean_squared_error(y_val, y_val_pred)\n","rmse = np.sqrt(mse)\n","print(\"Root Mean Squared Error (RMSE) with top features:\", rmse)\n","\n","# Prepare the test data for prediction using only top features\n","test2 = test.drop(['ID', 'date', 'day'], axis=1)\n","test2 = pd.DataFrame(scaler.transform(test2), columns=X.columns)\n","test2_top = test2[top_features]\n","\n","# Predict the burn area for the test set using the best model with top features\n","preds = best_model.predict(test2_top)\n","\n","# Add predictions to the submission dataframe\n","ss['burn_area'] = preds\n","\n","# Constrain predictions to the range (0, 1)\n","ss['burn_area'] = ss['burn_area'].clip(0, 1)\n","\n","# Save the submission file\n","ss.to_csv('/content/drive/My Drive/fire-extent-prediction-challenge/starter_submissionXGB43.csv', index=False)\n","\n","# Load and display the submission file\n","ss = pd.read_csv('/content/drive/My Drive/fire-extent-prediction-challenge/starter_submissionXGB43.csv')\n","print(ss.head())\n","\n","# Print value counts of burn_area in submission file\n","print(ss['burn_area'].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rInchFmaPazc","executionInfo":{"status":"ok","timestamp":1722927500636,"user_tz":-180,"elapsed":1712253,"user":{"displayName":"Solomon Kibon","userId":"04656160599927236118"}},"outputId":"f6708a8f-7c74-4eda-94bc-2c124008c534"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Best parameters found:  {'colsample_bytree': 0.6281664523398175, 'learning_rate': 0.07267561528460804, 'max_depth': 9, 'n_estimators': 391, 'reg_alpha': 0.3586467812961639, 'reg_lambda': 0.25416364906973876, 'subsample': 0.7181162353675755}\n","Feature importances:\n","          Feature  Importance\n","28          month    0.092137\n","3     climate_def    0.086243\n","0             lat    0.066755\n","22    landcover_5    0.063254\n","1             lon    0.062257\n","16      elevation    0.055239\n","13    climate_vap    0.045919\n","27           year    0.041125\n","9    climate_srad    0.040619\n","26  precipitation    0.036791\n","8    climate_soil    0.034956\n","21    landcover_4    0.031205\n","15     climate_vs    0.030798\n","11   climate_tmmn    0.030439\n","6      climate_pr    0.030236\n","23    landcover_6    0.029895\n","5     climate_pet    0.028714\n","2     climate_aet    0.028300\n","12   climate_tmmx    0.025582\n","19    landcover_2    0.024234\n","7      climate_ro    0.022332\n","14    climate_vpd    0.021941\n","4    climate_pdsi    0.021650\n","24    landcover_7    0.016398\n","25    landcover_8    0.012454\n","17    landcover_0    0.011895\n","18    landcover_1    0.008221\n","20    landcover_3    0.000410\n","10    climate_swe    0.000000\n","Top features selected for prediction: ['month' 'climate_def' 'lat' 'landcover_5' 'lon' 'elevation' 'climate_vap'\n"," 'year']\n","Root Mean Squared Error (RMSE) with top features: 0.020789928237537933\n","             ID  burn_area\n","0  0_2014-01-01   0.000314\n","1  1_2014-01-01   0.000088\n","2  2_2014-01-01   0.000237\n","3  3_2014-01-01   0.000075\n","4  4_2014-01-01   0.000082\n","burn_area\n","0.000000    11138\n","0.000141        4\n","0.000308        4\n","0.000547        4\n","0.000346        4\n","            ...  \n","0.016679        1\n","0.013138        1\n","0.011944        1\n","0.011117        1\n","0.000352        1\n","Name: count, Length: 14233, dtype: int64\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"b4vGWBI1JO8D"}}]}